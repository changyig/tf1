{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1280\n",
    "WIDTH = 32\n",
    "HEIGHT = 40\n",
    "NUM_CLASSES = 6\n",
    "iterations = 300\n",
    "  \n",
    "SAVER_DIR = \"train-saver/province/\"\n",
    "  \n",
    "PROVINCES = (\"京\",\"闽\",\"粤\",\"苏\",\"沪\",\"浙\")\n",
    "nProvinceIndex = 0\n",
    "  \n",
    "time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入节点，对应于图片像素值矩阵集合和图片标签(即所代表的数字)\n",
    "x = tf.placeholder(tf.float32, shape=[None, SIZE])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])\n",
    "  \n",
    "x_image = tf.reshape(x, [-1, WIDTH, HEIGHT, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积函数\n",
    "def conv_layer(inputs, W, b, conv_strides, kernel_size, pool_strides, padding):\n",
    "    L1_conv = tf.nn.conv2d(inputs, W, strides=conv_strides, padding=padding)\n",
    "    L1_relu = tf.nn.relu(L1_conv + b)\n",
    "    return tf.nn.max_pool(L1_relu, ksize=kernel_size, strides=pool_strides, padding='SAME')\n",
    "  \n",
    "# 定义全连接层函数\n",
    "def full_connect(inputs, W, b):\n",
    "    return tf.nn.relu(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1280)\n",
      "(1254, 1280)\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__' :\n",
    "  # 第一次遍历图片目录是为了获取图片总数\n",
    "    input_count = 0\n",
    "    for i in range(0,NUM_CLASSES):\n",
    "        dir = './car-datasets/tf_car_license_dataset/train_images/training-set/chinese-characters/%s/' % i #这里可以改成你自己的图片目录，i为分类标签\n",
    "        for rt, dirs, files in os.walk(dir):\n",
    "            for filename in files:\n",
    "                input_count += 1  \n",
    "  # 定义对应维数和各维长度的数组\n",
    "    input_images = np.array([[0]*SIZE for i in range(input_count)])\n",
    "    input_labels = np.array([[0]*NUM_CLASSES for i in range(input_count)])\n",
    "    # 第二次遍历图片目录是为了生成图片数据和标签\n",
    "    index = 0\n",
    "    for i in range(0,NUM_CLASSES):\n",
    "        dir = './car-datasets/tf_car_license_dataset/train_images/training-set/chinese-characters/%s/' % i     # 这里可以改成你自己的图片目录，i为分类标签\n",
    "        for rt, dirs, files in os.walk(dir):\n",
    "            for filename in files:\n",
    "                filename = dir + filename\n",
    "                img = Image.open(filename)\n",
    "                width = img.size[0]\n",
    "                height = img.size[1]\n",
    "                for h in range(0, height):\n",
    "                    for w in range(0, width):\n",
    "                    # 通过这样的处理，使数字的线条变细，有利于提高识别准确率\n",
    "                        if img.getpixel((w, h)) > 150:\n",
    "                            input_images[index][w+h*width] = 0\n",
    "                        else:\n",
    "                            input_images[index][w+h*width] = 1\n",
    "                input_labels[index][i] = 1\n",
    "                index += 1\n",
    "#             print(input_labels[index-1])\n",
    "#     print(input_images.shape)\n",
    "    \n",
    "    # 第一次遍历图片目录是为了获取图片总数\n",
    "    val_count = 0\n",
    "    for i in range(0,NUM_CLASSES):\n",
    "        dir = './car-datasets/tf_car_license_dataset/train_images/validation-set/chinese-characters/%s/' % i #这里可以改成你自己的图片目录，i为分类标签\n",
    "        for rt, dirs, files in os.walk(dir):\n",
    "            for filename in files:\n",
    "                val_count += 1  \n",
    "  # 定义对应维数和各维长度的数组\n",
    "    val_images = np.array([[0]*SIZE for i in range(val_count)])\n",
    "    val_labels = np.array([[0]*NUM_CLASSES for i in range(val_count)])\n",
    "    # 第二次遍历图片目录是为了生成图片数据和标签\n",
    "    index = 0\n",
    "    for i in range(0,NUM_CLASSES):\n",
    "        dir = './car-datasets/tf_car_license_dataset/train_images/validation-set/chinese-characters/%s/' % i     # 这里可以改成你自己的图片目录，i为分类标签\n",
    "        for rt, dirs, files in os.walk(dir):\n",
    "            for filename in files:\n",
    "                filename = dir + filename\n",
    "                img = Image.open(filename)\n",
    "                width = img.size[0]\n",
    "                height = img.size[1]\n",
    "                for h in range(0, height):\n",
    "                    for w in range(0, width):\n",
    "                    # 通过这样的处理，使数字的线条变细，有利于提高识别准确率\n",
    "                        if img.getpixel((w, h)) > 150:\n",
    "                            val_images[index][w+h*width] = 0\n",
    "                        else:\n",
    "                            val_images[index][w+h*width] = 1\n",
    "                val_labels[index][i] = 1\n",
    "                index += 1\n",
    "    print(val_images.shape)\n",
    "    print(input_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(0,15,1):\n",
    "    num=random.randint(0,179)\n",
    "    image=input_images[num].reshape(40,32)\n",
    "    lable='jing'\n",
    "    plt.subplot(3,5,i+1) # 绘制前15个手写体数字，以3行6列子图形式展示\n",
    "    plt.tight_layout() # 自动适配\n",
    "    plt.imshow(image, cmap='Greys') # 使用灰色显示像素灰度值\n",
    "    plt.title(\"Label: {}\".format(lable)) # 设置标签为子图标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: W_conv1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3d775c50d6db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m      \u001b[1;31m# 初始化saver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_eager_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[0;32m   1282\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[0;32m   1285\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m       \u001b[1;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[1;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Graph mode needs to build save and restore together.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m     \u001b[0msaveables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[1;34m(self, names_to_saveables)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \"\"\"\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m       \u001b[0mnames_to_saveables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[1;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[1;32m--> 561\u001b[1;33m                              name)\n\u001b[0m\u001b[0;32m    562\u001b[0m           \u001b[0mnames_to_saveables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least two variables have the same name: W_conv1"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    \n",
    "    # 第一个卷积层\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([8, 8, 1, 16], stddev=0.1), name=\"W_conv1\")\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]), name=\"b_conv1\")\n",
    "    conv_strides = [1, 1, 1, 1]\n",
    "    kernel_size = [1, 2, 2, 1]\n",
    "    pool_strides = [1, 2, 2, 1]\n",
    "    L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "    \n",
    "    # 第二个卷积层\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 16, 32], stddev=0.1), name=\"W_conv2\")\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]), name=\"b_conv2\")\n",
    "    conv_strides = [1, 1, 1, 1]\n",
    "    kernel_size = [1, 1, 1, 1]\n",
    "    pool_strides = [1, 1, 1, 1]\n",
    "    L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "    \n",
    "    # 全连接层\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([16 * 20 * 32, 512], stddev=0.1), name=\"W_fc1\")\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1, shape=[512]), name=\"b_fc1\")\n",
    "    h_pool2_flat = tf.reshape(L2_pool, [-1, 16 * 20*32])\n",
    "    h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
    "    \n",
    "    # dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)  \n",
    "    \n",
    "    # readout层\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([512, NUM_CLASSES], stddev=0.1), name=\"W_fc2\")\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1, shape=[NUM_CLASSES]), name=\"b_fc2\")\n",
    "  \n",
    "    # 定义优化器和训练op\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
    "  \n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "     # 初始化saver\n",
    "    saver = tf.train.Saver()\n",
    "  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "    time_elapsed = time.time() - time_begin\n",
    "    print(\"读取图片文件耗费时间：%d秒\" % time_elapsed)\n",
    "    time_begin = time.time()\n",
    "  \n",
    "    print (\"一共读取了 %s 个训练图像， %s 个标签\" % (input_count, input_count))\n",
    "  \n",
    "    # 设置每次训练op的输入个数和迭代次数，这里为了支持任意图片总数，定义了一个余数remainder，譬如，如果每次训练op的输入个数为60，图片总数为150张，则前面两次各输入60张，最后一次输入30张（余数30）\n",
    "    batch_size = 60\n",
    "    iterations = iterations\n",
    "    batches_count = int(input_count / batch_size)\n",
    "    remainder = input_count % batch_size\n",
    "    print (\"训练数据集分成 %s 批, 前面每批 %s 个数据，最后一批 %s 个数据\" % (batches_count+1, batch_size, remainder))\n",
    "  \n",
    "    # 执行训练迭代\n",
    "    for it in range(iterations):\n",
    "        # 这里的关键是要把输入数组转为np.array\n",
    "        for n in range(batches_count):\n",
    "            train_step.run(feed_dict={x: input_images[n*batch_size:(n+1)*batch_size], y_: input_labels[n*batch_size:(n+1)*batch_size], keep_prob: 0.5})\n",
    "        if remainder > 0:\n",
    "            start_index = batches_count * batch_size;\n",
    "        train_step.run(feed_dict={x: input_images[start_index:input_count-1], y_: input_labels[start_index:input_count-1], keep_prob: 0.5})\n",
    "  \n",
    "      # 每完成五次迭代，判断准确度是否已达到100%，达到则退出迭代循环\n",
    "        iterate_accuracy = 0\n",
    "        if it%5 == 0:\n",
    "            iterate_accuracy = accuracy.eval(feed_dict={x: val_images, y_: val_labels, keep_prob: 1.0})\n",
    "            print ('第 %d 次训练迭代: 准确率 %0.5f%%' % (it, iterate_accuracy*100))\n",
    "            if iterate_accuracy >= 0.9999 :\n",
    "                break;\n",
    "  \n",
    "    print ('完成训练!')\n",
    "    time_elapsed = time.time() - time_begin\n",
    "    print (\"训练耗费时间：%d秒\" % time_elapsed)\n",
    "    time_begin = time.time()\n",
    "  \n",
    "    # 保存训练结果\n",
    "    if not os.path.exists(SAVER_DIR):\n",
    "        print ('不存在训练数据保存目录，现在创建保存目录')\n",
    "        os.makedirs(SAVER_DIR)\n",
    "    saver_path = saver.save(sess, \"%smodel.ckpt\"%(SAVER_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_img(img,name):\n",
    "#     plt.imshow(img) # 使用灰色显示像素灰度值\n",
    "#     plt.title(\"Label: {}\".format(name)) # 设置标签为子图标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from train-saver/province/model.ckpt\n",
      "Tensor(\"W_conv1:0\", shape=(8, 8, 1, 16), dtype=float32_ref)\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value b_conv1\n\t [[Node: _retval_b_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](b_conv1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value b_conv1\n\t [[Node: _retval_b_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](b_conv1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-003c70ea3142>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mb_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"b_conv1:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_conv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_conv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mconv_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value b_conv1\n\t [[Node: _retval_b_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](b_conv1)]]"
     ]
    }
   ],
   "source": [
    "# if __name__ =='__main__' :\n",
    "#     saver = tf.train.import_meta_graph(\"%smodel.ckpt.meta\"%(SAVER_DIR))\n",
    "#     with tf.Session() as sess:\n",
    "#         model_file=tf.train.latest_checkpoint(SAVER_DIR)\n",
    "#         saver.restore(sess, model_file)\n",
    "\n",
    "#         # 第一个卷积层\n",
    "#         W_conv1 = sess.graph.get_tensor_by_name(\"W_conv1:0\")\n",
    "#         b_conv1 = sess.graph.get_tensor_by_name(\"b_conv1:0\")\n",
    "#         print(W_conv1)\n",
    "#         print(sess.run(b_conv1))\n",
    "#         conv_strides = [1, 1, 1, 1]\n",
    "#         kernel_size = [1, 2, 2, 1]\n",
    "#         pool_strides = [1, 2, 2, 1]\n",
    "#         print(W_conv1)\n",
    "#         L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "\n",
    "#         # 第二个卷积层\n",
    "#         W_conv2 = sess.graph.get_tensor_by_name(\"W_conv2:0\")\n",
    "#         b_conv2 = sess.graph.get_tensor_by_name(\"b_conv2:0\")\n",
    "#         conv_strides = [1, 1, 1, 1]\n",
    "#         kernel_size = [1, 1, 1, 1]\n",
    "#         pool_strides = [1, 1, 1, 1]\n",
    "#         L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "\n",
    "#         # 全连接层\n",
    "#         W_fc1 = sess.graph.get_tensor_by_name(\"W_fc1:0\")\n",
    "#         b_fc1 = sess.graph.get_tensor_by_name(\"b_fc1:0\")\n",
    "#         h_pool2_flat = tf.reshape(L2_pool, [-1, 16 * 20*32])\n",
    "#         h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
    "\n",
    "\n",
    "#         # dropout\n",
    "#         keep_prob = tf.placeholder(tf.float32)\n",
    "#         h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "#         # readout层\n",
    "#         W_fc2 = sess.graph.get_tensor_by_name(\"W_fc2:0\")\n",
    "#         b_fc2 = sess.graph.get_tensor_by_name(\"b_fc2:0\")\n",
    "\n",
    "#         # 定义优化器和训练op\n",
    "#         conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "        \n",
    "#         for n in range(1,2):\n",
    "#             path = \"test_images/%s.bmp\" % (n)\n",
    "#             img = Image.open(path)\n",
    "#             show_img(img,n)\n",
    "#             width = img.size[0]\n",
    "#             height = img.size[1]\n",
    "#             img_data = [[0]*SIZE for i in range(1)]\n",
    "#             for h in range(0, height):\n",
    "#                 for w in range(0, width):\n",
    "#                     if img.getpixel((w, h)) < 190:\n",
    "#                         img_data[0][w+h*width] = 1\n",
    "#                     else:\n",
    "#                         img_data[0][w+h*width] = 0\n",
    "\n",
    "#             result = sess.run(conv, feed_dict = {x: np.array(img_data), keep_prob: 1.0})\n",
    "#             print(result)\n",
    "#             max1 = 0\n",
    "#             max2 = 0\n",
    "#             max3 = 0\n",
    "#             max1_index = 0\n",
    "#             max2_index = 0\n",
    "#             max3_index = 0\n",
    "#             for j in range(NUM_CLASSES):\n",
    "#                 if result[0][j] > max1:\n",
    "#                     max1 = result[0][j]\n",
    "#                     max1_index = j\n",
    "#                     continue\n",
    "#                 if (result[0][j]>max2) and (result[0][j]<=max1):\n",
    "#                     max2 = result[0][j]\n",
    "#                     max2_index = j\n",
    "#                     continue\n",
    "#                 if (result[0][j]>max3) and (result[0][j]<=max2):\n",
    "#                     max3 = result[0][j]\n",
    "#                     max3_index = j\n",
    "#                     continue\n",
    "\n",
    "#                 nProvinceIndex = max1_index\n",
    "#             print (\"概率： [%s %0.2f%%]  [%s %0.2f%%]  [%s %0.2f%%]\" % (PROVINCES[max1_index],max1*100, PROVINCES[max2_index],max2*100, PROVINCES[max3_index],max3*100))\n",
    "\n",
    "#             print (\"省份简称是: %s\" % PROVINCES[nProvinceIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
