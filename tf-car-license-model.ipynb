{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "  \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1280\n",
    "WIDTH = 32\n",
    "HEIGHT = 40\n",
    "NUM_CLASSES = 6\n",
    "iterations = 30\n",
    "  \n",
    "SAVER_DIR = \"./train-saver/province/\"\n",
    "  \n",
    "PROVINCES = (\"京\",\"闽\",\"粤\",\"苏\",\"沪\",\"浙\")\n",
    "nProvinceIndex = 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义输入节点，对应于图片像素值矩阵集合和图片标签(即所代表的数字)\n",
    "x = tf.placeholder(tf.float32, shape=[None, SIZE])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])\n",
    "  \n",
    "x_image = tf.reshape(x, [-1, WIDTH, HEIGHT, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '定义卷积函数' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-9eac874fed46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m定义卷积函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_strides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_strides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mL1_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv_strides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mL1_relu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL1_conv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL1_relu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_strides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '定义卷积函数' is not defined"
     ]
    }
   ],
   "source": [
    "定义卷积函数\n",
    "def conv_layer(inputs, W, b, conv_strides, kernel_size, pool_strides, padding):\n",
    "    L1_conv = tf.nn.conv2d(inputs, W, strides=conv_strides, padding=padding)\n",
    "    L1_relu = tf.nn.relu(L1_conv + b)\n",
    "    return tf.nn.max_pool(L1_relu, ksize=kernel_size, strides=pool_strides, padding='SAME')\n",
    "  \n",
    "# 定义全连接层函数\n",
    "def full_connect(inputs, W, b):\n",
    "    return tf.nn.relu(tf.matmul(inputs, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "    \n",
    "    # 第一个卷积层\n",
    "#     W_conv1 = tf.Variable(tf.truncated_normal([8, 8, 1, 16], stddev=0.2), name=\"W_conv1\")\n",
    "#     b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]), name=\"b_conv1\")\n",
    "#     conv_strides = [1, 1, 1, 1]\n",
    "#     kernel_size = [1, 2, 2, 1]\n",
    "#     pool_strides = [1, 2, 2, 1]\n",
    "#     L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "    \n",
    "#     # 第二个卷积层\n",
    "#     W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 16, 32], stddev=0.1), name=\"W_conv2\")\n",
    "#     b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]), name=\"b_conv2\")\n",
    "#     conv_strides = [1, 1, 1, 1]\n",
    "#     kernel_size = [1, 1, 1, 1]\n",
    "#     pool_strides = [1, 1, 1, 1]\n",
    "#     L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "    \n",
    "#     # 全连接层\n",
    "#     W_fc1 = tf.Variable(tf.truncated_normal([16 * 20 * 32, 512], stddev=0.1), name=\"W_fc1\")\n",
    "#     b_fc1 = tf.Variable(tf.constant(0.1, shape=[512]), name=\"b_fc1\")\n",
    "#     h_pool2_flat = tf.reshape(L2_pool, [-1, 16 * 20*32])\n",
    "#     h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
    "    \n",
    "#     # dropout\n",
    "#     keep_prob = tf.placeholder(tf.float32)\n",
    "#     h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)  \n",
    "    \n",
    "#     # readout层\n",
    "#     W_fc2 = tf.Variable(tf.truncated_normal([512, NUM_CLASSES], stddev=0.1), name=\"W_fc2\")\n",
    "#     b_fc2 = tf.Variable(tf.constant(0.1, shape=[NUM_CLASSES]), name=\"b_fc2\")\n",
    "  \n",
    "#     # 定义优化器和训练op\n",
    "#     y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "#     cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#     train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
    "  \n",
    "#     correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# #     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(train_step)\n",
    "#     saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img,name):\n",
    "    plt.imshow(img) # 使用灰色显示像素灰度值\n",
    "    plt.title(\"Label: {}\".format(name)) # 设置标签为子图标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.saver.Saver object at 0x000000002C807358>\n",
      "./train-saver/province/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./train-saver/province/model.ckpt\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value W_conv1\n\t [[Node: _retval_W_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W_conv1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value W_conv1\n\t [[Node: _retval_W_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W_conv1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-543428e01e69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# 第一个卷积层\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mW_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W_conv1:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         b_conv1 = sess.run(tf.get_default_graph().get_tensor_by_name(\"b_conv1:0\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value W_conv1\n\t [[Node: _retval_W_conv1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W_conv1)]]"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__' :\n",
    "    saver = tf.train.import_meta_graph(\"%smodel.ckpt.meta\"%(SAVER_DIR))\n",
    "    print(saver)\n",
    "    with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "        model_file=tf.train.latest_checkpoint(SAVER_DIR)\n",
    "        print(model_file)\n",
    "        saver.restore(sess, model_file)\n",
    "#         saver.restore(sess, SAVER_DIR)\n",
    "\n",
    "        # 第一个卷积层\n",
    "        W_conv1 = sess.run(tf.get_default_graph().get_tensor_by_name(\"W_conv1:0\"))\n",
    "#         b_conv1 = sess.run(tf.get_default_graph().get_tensor_by_name(\"b_conv1:0\"))\n",
    "        print(W_conv)\n",
    "#         print(sess.run(b_conv1))\n",
    "#         conv_strides = [1, 1, 1, 1]\n",
    "#         kernel_size = [1, 2, 2, 1]\n",
    "#         pool_strides = [1, 2, 2, 1]\n",
    "#         print(W_conv1)\n",
    "#         L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "\n",
    "#         # 第二个卷积层\n",
    "#         W_conv2 = sess.graph.get_tensor_by_name(\"W_conv2:0\")\n",
    "#         b_conv2 = sess.graph.get_tensor_by_name(\"b_conv2:0\")\n",
    "#         conv_strides = [1, 1, 1, 1]\n",
    "#         kernel_size = [1, 1, 1, 1]\n",
    "#         pool_strides = [1, 1, 1, 1]\n",
    "#         L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
    "\n",
    "#         # 全连接层\n",
    "#         W_fc1 = sess.graph.get_tensor_by_name(\"W_fc1:0\")\n",
    "#         b_fc1 = sess.graph.get_tensor_by_name(\"b_fc1:0\")\n",
    "#         h_pool2_flat = tf.reshape(L2_pool, [-1, 16 * 20*32])\n",
    "#         h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
    "\n",
    "\n",
    "#         # dropout\n",
    "#         keep_prob = tf.placeholder(tf.float32)\n",
    "#         h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "#         # readout层\n",
    "#         W_fc2 = sess.graph.get_tensor_by_name(\"W_fc2:0\")\n",
    "#         b_fc2 = sess.graph.get_tensor_by_name(\"b_fc2:0\")\n",
    "\n",
    "#         # 定义优化器和训练op\n",
    "#         conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "        \n",
    "#         for n in range(1,5):\n",
    "#             plt.subplot(1,5,n)\n",
    "#             path = \"test_images/%s.bmp\" % (n)\n",
    "#             img = Image.open(path)\n",
    "#             show_img(img,n)\n",
    "#             width = img.size[0]\n",
    "#             height = img.size[1]\n",
    "#             img_data = [[0]*SIZE for i in range(1)]\n",
    "#             for h in range(0, height):\n",
    "#                 for w in range(0, width):\n",
    "#                     if img.getpixel((w, h)) < 190:\n",
    "#                         img_data[0][w+h*width] = 1\n",
    "#                     else:\n",
    "#                         img_data[0][w+h*width] = 0\n",
    "\n",
    "#             result = sess.run(conv, feed_dict = {x: np.array(img_data), keep_prob: 1.0})\n",
    "# #             print(result)\n",
    "#             max1 = 0\n",
    "#             max2 = 0\n",
    "#             max3 = 0\n",
    "#             max1_index = 0\n",
    "#             max2_index = 0\n",
    "#             max3_index = 0\n",
    "#             for j in range(NUM_CLASSES):\n",
    "#                 if result[0][j] > max1:\n",
    "#                     max1 = result[0][j]\n",
    "#                     max1_index = j\n",
    "#                     continue\n",
    "#                 if (result[0][j]>max2) and (result[0][j]<=max1):\n",
    "#                     max2 = result[0][j]\n",
    "#                     max2_index = j\n",
    "#                     continue\n",
    "#                 if (result[0][j]>max3) and (result[0][j]<=max2):\n",
    "#                     max3 = result[0][j]\n",
    "#                     max3_index = j\n",
    "#                     continue\n",
    "\n",
    "#                 nProvinceIndex = max1_index\n",
    "#             print (\"概率： [%s %0.2f%%]  [%s %0.2f%%]  [%s %0.2f%%]\" % (PROVINCES[max1_index],max1*100, PROVINCES[max2_index],max2*100, PROVINCES[max3_index],max3*100))\n",
    "#             print (\"省份简称是: %s\" % PROVINCES[nProvinceIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
